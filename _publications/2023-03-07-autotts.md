---
layout: post
comments: true
title: "Differentiable Duration Modeling for End-to-End Text-to-Speech"
date: 2023-03-07 12:00:00
tags: text-to-speech
---

> Parallel text-to-speech (TTS) models have recently enabled fast and highly-natural speech synthesis. However, such models typically require external alignment models, which are not necessarily optimized for the decoder as they are not jointly trained. In this paper, we propose a differentiable duration method for learning monotonic alignments between input and output sequences. Our method is based on a soft-duration mechanism that optimizes a stochastic process in expectation. Using this differentiable duration method, a direct text to waveform TTS model is introduced to produce raw audio as output instead of performing neural vocoding. Our model learns to perform high-fidelity speech synthesis through a combination of adversarial training and matching the total ground-truth duration. Experimental results show that our model obtains competitive results while enjoying a much simpler training pipeline.
<!--more-->

For for information, please go to our webpage https://sony.github.io/ai-research-code/autotts/demo/